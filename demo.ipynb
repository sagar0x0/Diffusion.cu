{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed948386",
   "metadata": {},
   "source": [
    "# Kaggle notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a13d15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required dependencies with PyTorch development headers\n",
    "!pip install huggingface_hub transformers accelerate pybind11\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!apt-get update && apt-get install -y cmake build-essential\n",
    "!pip install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18869f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copy source files to working directory\n",
    "import shutil\n",
    "import os\n",
    "import pybind11\n",
    "import torch\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('/kaggle/working/Diffusion.cu/cuda_kernel', exist_ok=True)\n",
    "os.makedirs('/kaggle/working/Diffusion.cu/diffusion_model', exist_ok=True)\n",
    "\n",
    "# Copy CUDA kernel files to be able to execute & write access\n",
    "shutil.copy2('/kaggle/input/diff12/Diffusion.cu/cuda_kernel/flash_atten.cu', '/kaggle/working/Diffusion.cu/cuda_kernel/')\n",
    "shutil.copy2('/kaggle/input/diff12/Diffusion.cu/cuda_kernel/groupnorm.cu', '/kaggle/working/Diffusion.cu/cuda_kernel/')\n",
    "shutil.copy2('/kaggle/input/diff12/Diffusion.cu/cuda_kernel/conv2d_k3.cu', '/kaggle/working/Diffusion.cu/cuda_kernel/')\n",
    "\n",
    "# Copy CMakeLists.txt\n",
    "shutil.copy2('/kaggle/input/diff12/Diffusion.cu/CMakeLists.txt', '/kaggle/working/Diffusion.cu/')\n",
    "\n",
    "# Create build directory and compile\n",
    "os.makedirs('/kaggle/working/Diffusion.cu/build', exist_ok=True)\n",
    "%cd /kaggle/working/Diffusion.cu/build\n",
    "# now we are in build dir\n",
    "\n",
    "pybind11_dir = pybind11.get_cmake_dir()\n",
    "torch_dir = torch.utils.cmake_prefix_path\n",
    "\n",
    "print(f\"Pybind11 CMake directory: {pybind11_dir}\")\n",
    "print(f\"Torch CMake directory: {torch_dir}\")\n",
    "\n",
    "# Configure and build with both pybind11 and torch paths\n",
    "!cmake .. -Dpybind11_DIR={pybind11_dir} -DTorch_DIR={torch_dir}/Torch -DCMAKE_BUILD_TYPE=Release\n",
    "!make -j4\n",
    "\n",
    "# Check if compilation was successful\n",
    "print(\"Compilation output:\")\n",
    "!ls -la *.so\n",
    "\n",
    "# Add the compiled modules to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/Diffusion.cu/build')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390f4e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copy all Python files from diffusion_model\n",
    "import glob\n",
    "\n",
    "python_files = glob.glob('/kaggle/input/diff12/Diffusion.cu/diffusion_model/*.py')\n",
    "for file_path in python_files:\n",
    "    shutil.copy2(file_path, '/kaggle/working/Diffusion.cu/diffusion_model/')\n",
    "\n",
    "# Add both directories to Python path\n",
    "sys.path.insert(0, '/kaggle/working/Diffusion.cu/diffusion_model')\n",
    "sys.path.insert(0, '/kaggle/working/Diffusion.cu/build')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b443ac0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# First, let's check what modules are actually available\n",
    "import os\n",
    "print(\"Available compiled modules:\")\n",
    "for file in os.listdir('/kaggle/working/Diffusion.cu/build'):\n",
    "    if file.endswith('.so'):\n",
    "        print(f\"  {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841eb484",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from transformers import CLIPTokenizer\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Add paths\n",
    "sys.path.insert(0, '/kaggle/working/Diffusion.cu/diffusion_model')\n",
    "sys.path.insert(0, '/kaggle/working/Diffusion.cu/build')\n",
    "\n",
    "try:\n",
    "    import model_loader\n",
    "    import pipeline\n",
    "    print(\"✓ Successfully imported model_loader and pipeline\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Failed to import custom modules: {e}\")\n",
    "    # Try alternative import\n",
    "    try:\n",
    "        from diffusion_model import model_loader, pipeline\n",
    "        print(\"✓ Successfully imported from diffusion_model\")\n",
    "    except ImportError as e2:\n",
    "        print(f\"✗ Alternative import also failed: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b6f26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# GPU Configuration for Kaggle\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ALLOW_CUDA = True\n",
    "\n",
    "if torch.cuda.is_available() and ALLOW_CUDA:\n",
    "    DEVICE = \"cuda\"\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac20eb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create working directories in Kaggle\n",
    "os.makedirs('/kaggle/working/data', exist_ok=True)\n",
    "os.makedirs('/kaggle/working/images', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80235fbc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download tokenizer files from Hugging Face\n",
    "print(\"Downloading tokenizer files...\")\n",
    "try:\n",
    "    vocab_path = hf_hub_download(\n",
    "        repo_id=\"sd-legacy/stable-diffusion-v1-5\",\n",
    "        filename=\"tokenizer/vocab.json\",\n",
    "        cache_dir=\"/kaggle/working/data\",\n",
    "        force_download=True\n",
    "    )\n",
    "    merges_path = hf_hub_download(\n",
    "        repo_id=\"sd-legacy/stable-diffusion-v1-5\", \n",
    "        filename=\"tokenizer/merges.txt\",\n",
    "        cache_dir=\"/kaggle/working/data\",\n",
    "        force_download=True\n",
    "    )\n",
    "    print(\"Tokenizer files downloaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading tokenizer files: {e}\")\n",
    "    # Fallback: try to use paths from your dataset if they exist\n",
    "    vocab_path = \"/kaggle/working/data/vocab.json\"\n",
    "    merges_path = \"/kaggle/working/data/merges.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bb3cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download model weights\n",
    "print(\"Downloading model weights...\")\n",
    "try:\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=\"sd-legacy/stable-diffusion-v1-5\",\n",
    "        filename=\"v1-5-pruned-emaonly.ckpt\",\n",
    "        cache_dir=\"/kaggle/working/data\",\n",
    "        force_download=True\n",
    "    )\n",
    "    print(\"Model weights downloaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading model weights: {e}\")\n",
    "    # If download fails, you might need to manually upload the model to Kaggle dataset\n",
    "    model_path = \"/kaggle/working/data/v1-5-pruned-emaonly.ckpt\"\n",
    "    print(\"Please ensure model weights are available at the above path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152912d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "try:\n",
    "    tokenizer = CLIPTokenizer(vocab_path, merges_file=merges_path)\n",
    "    print(\"Tokenizer initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing tokenizer: {e}\")\n",
    "    # Try alternative path\n",
    "    try:\n",
    "        tokenizer = CLIPTokenizer(\"/kaggle/working/data/tokenizer/vocab.json\", \n",
    "                                merges_file=\"/kaggle/working/data/tokenizer/merges.txt\")\n",
    "    except:\n",
    "        print(\"Failed to initialize tokenizer. Please check file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59af01e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "models = model_loader.preload_models_from_standard_weights(model_path, DEVICE)\n",
    "print(\"Models loaded successfully\")\n",
    "\n",
    "# Clear GPU cache if using CUDA\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f809d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Only proceed if models were loaded successfully\n",
    "if models is not None:\n",
    "    # TEXT TO IMAGE\n",
    "    prompt = \"A cat stretching on the floor, highly detailed, ultra sharp, cinematic, 100mm lens, 8k resolution.\"\n",
    "    uncond_prompt = \"\"  # Also known as negative prompt\n",
    "    do_cfg = True\n",
    "    cfg_scale = 8  # min: 1, max: 14\n",
    "\n",
    "    # IMAGE TO IMAGE (disabled by default)\n",
    "    input_image = None\n",
    "    # Uncomment for image-to-image\n",
    "    # image_path = \"/kaggle/working/images/input.jpg\"\n",
    "    # input_image = Image.open(image_path)\n",
    "    strength = 0.9\n",
    "\n",
    "    # SAMPLER\n",
    "    sampler = \"ddpm\"\n",
    "    num_inference_steps = 30  # Reduced for faster generation on Kaggle\n",
    "    seed = 42\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f509607",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Starting image generation on {DEVICE}...\")\n",
    "\n",
    "# Time the generation\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "if models is not None:  # ✅ This is line 41\n",
    "    try:\n",
    "        output_image = pipeline.generate(\n",
    "            prompt=prompt,\n",
    "            uncond_prompt=uncond_prompt,\n",
    "            input_image=input_image,\n",
    "            strength=strength,\n",
    "            do_cfg=do_cfg,\n",
    "            cfg_scale=cfg_scale,\n",
    "            sampler_name=sampler,\n",
    "            n_inference_steps=num_inference_steps,\n",
    "            seed=seed,\n",
    "            models=models,\n",
    "            device=DEVICE,\n",
    "            idle_device=\"cuda\" if DEVICE == \"cuda\" else \"cpu\",\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Image generation completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        # Save and display the image\n",
    "        output_path = \"/kaggle/working/generated_image.png\"\n",
    "        Image.fromarray(output_image).save(output_path)\n",
    "        print(f\"Image saved to: {output_path}\")\n",
    "        \n",
    "        # Display the image\n",
    "        display(Image.fromarray(output_image))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during image generation: {e}\")\n",
    "        print(\"This might be due to:\")\n",
    "        print(\"1. Memory issues - try reducing num_inference_steps\")\n",
    "        print(\"2. Model compatibility issues\")\n",
    "        print(\"3. Missing dependencies\")\n",
    "else:  # ✅ This should be at the same indentation level as the 'if' statement\n",
    "    print(\"Cannot generate image - models failed to load\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
